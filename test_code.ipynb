{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S Mamba code: https://github.com/wzhwzhwzh0921/S-D-Mamba/blob/main/model/S_Mamba.py\n",
    "\n",
    "Mamba code: https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba2_simple.py\n",
    "\n",
    "Graph NN code:https://github.com/pyg-team/pytorch_geometric \n",
    "\n",
    "Data Reference: https://www.kaggle.com/datasets/ehoseinz/cnnpred-stock-market-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pip-tools\n",
    "# pip-compile requirements.txt --output-file resolved_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'processed_data' from 'Utils.Loading_data' (/Users/mac/Documents/2. GitHub/MAMBA_model/Utils/Loading_data.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from Utils.Loading_data import labels_plotting\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mModels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mML_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_ML_models\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# labels_plotting()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m run_ML_models()\n",
      "File \u001b[0;32m~/Documents/2. GitHub/MAMBA_model/Models/ML_models.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mUtils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoading_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m processed_data\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mUtils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEvaluation_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m information_coefficient, rank_information_coefficient\n\u001b[1;32m     12\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'processed_data' from 'Utils.Loading_data' (/Users/mac/Documents/2. GitHub/MAMBA_model/Utils/Loading_data.py)"
     ]
    }
   ],
   "source": [
    "# from Utils.Loading_data import labels_plotting\n",
    "# from Models.ML_models import run_ML_models\n",
    "\n",
    "# labels_plotting()\n",
    "# run_ML_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current parameters: num_layers=6, d_state=64, K=3\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# from Utils.Loading_data import processed_data\n",
    "# from Models.DL_models import GRAPH_MAMBA\n",
    "# import numpy as np\n",
    "# from types import SimpleNamespace\n",
    "# import itertools\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# # Define the hyperparameter search space\n",
    "# param_grid = {\n",
    "#     'num_layers': [6, 8], \n",
    "#     'd_state': [64, 128, 256], \n",
    "#     'K': [3, 5, 7], \n",
    "#     # 'out_channels': [32, 64, 128], \n",
    "# }\n",
    "\n",
    "# # Create all combinations of hyperparameters using itertools.product\n",
    "# param_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------NASDAQ------------------------------\n",
      "x_train shape: torch.Size([888, 82, 5])\n",
      "y_train shape: torch.Size([888, 1])\n",
      "x_test shape: torch.Size([167, 82, 5])\n",
      "y_test shape: torch.Size([167])\n",
      "x_val shape: torch.Size([55, 82, 5])\n",
      "y_val shape: torch.Size([55])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|███████████████████████████████████████| 7/7 [00:54<00:00,  7.84s/batch, loss=1.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 9.5514, Validation Loss: 0.9665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|███████████████████████████████████████| 7/7 [00:54<00:00,  7.84s/batch, loss=1.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 9.2359, Validation Loss: 0.9033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|████████████████████████████████████████| 7/7 [00:54<00:00,  7.83s/batch, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 9.2906, Validation Loss: 0.8791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|███████████████████████████████████████| 7/7 [00:51<00:00,  7.39s/batch, loss=1.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 9.1069, Validation Loss: 0.8770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████████████████████████████████| 7/7 [00:48<00:00,  6.91s/batch, loss=0.955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 8.9454, Validation Loss: 0.8768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████████████████████████████████| 7/7 [00:48<00:00,  6.90s/batch, loss=0.959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 9.0095, Validation Loss: 0.8771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|███████████████████████████████████████| 7/7 [00:47<00:00,  6.86s/batch, loss=1.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 8.8487, Validation Loss: 0.8797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████████████████████████████████| 7/7 [00:46<00:00,  6.68s/batch, loss=0.944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 8.6989, Validation Loss: 0.8844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|███████████████████████████████████████| 7/7 [00:46<00:00,  6.67s/batch, loss=1.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 8.9286, Validation Loss: 0.8874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  29%|███████████▋                             | 2/7 [00:13<00:34,  6.90s/batch, loss=1]"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from types import SimpleNamespace\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from Utils.Loading_data import Get_data\n",
    "from Models.DL_models import GRAPH_MAMBA\n",
    "import tqdm\n",
    "from Utils.Evaluation_metrics import information_coefficient, rank_information_coefficient, RMSE\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "\n",
    "weight_path = \"Weights\"\n",
    "lr = 1e-4\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "plot_save_path = \"Results\"\n",
    "data_path = \"Data\"\n",
    "\n",
    "# Model configuration\n",
    "configs = SimpleNamespace(\n",
    "    seq_len=5,        # Sequence length, L=5\n",
    "    pred_len=1,        # Prediction length\n",
    "    num_layers=3,      # R=3\n",
    "    d_model=64,       # E=64\n",
    "    d_state=64,        # H=64\n",
    "    ker_size=2,       \n",
    "    hidden_dimention=32,  # U=32 \n",
    "    parallel=False,   \n",
    "    linear_depth=82, \n",
    "    node_num=82,      # N=82\n",
    "    embed_dim=10,    # de=10\n",
    "    feature_dim=5,   # L=5\n",
    "    cheb_k=3         # K=3\n",
    ")\n",
    "\n",
    "batch_size = batch_size\n",
    "processed_data = Get_data(data_path)\n",
    "\n",
    "for dataset_name, dataset in processed_data.items():\n",
    "    print('\\n' + '-'*30 + f'{dataset_name}' + '-'*30)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = GRAPH_MAMBA(configs)\n",
    "    # if os.path.exists(f'{weight_path}/{dataset_name}.pth'):\n",
    "    #     model.load_state_dict(torch.load(f'{weight_path}/{dataset_name}.pth'))  \n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # Use learning rate from the arguments\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    x_train = torch.tensor(dataset['X_train'], dtype=torch.float32)\n",
    "    y_train = torch.tensor(dataset['y_train'], dtype=torch.float32).unsqueeze(-1)\n",
    "    x_test = torch.tensor(dataset['X_test'], dtype=torch.float32)\n",
    "    y_test = torch.tensor(dataset['y_test'], dtype=torch.float32)\n",
    "    x_val = torch.tensor(dataset['X_val'], dtype=torch.float32)\n",
    "    y_val = torch.tensor(dataset['y_val'], dtype=torch.float32)\n",
    "\n",
    "    print(f\"x_train shape: {x_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"x_test shape: {x_test.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "    print(f\"x_val shape: {x_val.shape}\")\n",
    "    print(f\"y_val shape: {y_val.shape}\")\n",
    "\n",
    "    train_dataset = TensorDataset(x_train, y_train)\n",
    "    test_dataset = TensorDataset(x_test, y_test)\n",
    "    val_dataset = TensorDataset(x_val, y_val)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    num_epochs = epochs\n",
    "    # lr_patience = 2  \n",
    "    # best_loss = float('inf')  \n",
    "    # no_improvement = 0  \n",
    "\n",
    "    # ----------------------------------------------- Training process -----------------------------------------------\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        with tqdm.tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", ncols=100, unit=\"batch\") as train_bar:\n",
    "            for batch_x, batch_y in train_bar:\n",
    "                optimizer.zero_grad()\n",
    "                output = model(batch_x)\n",
    "                loss = criterion(output, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                train_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  \n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                val_output = torch.squeeze(model(batch_x))\n",
    "                loss = criterion(val_output, batch_y)\n",
    "                val_loss += loss.item()\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "        # if val_loss < best_loss:\n",
    "        #     best_loss = val_loss\n",
    "        #     no_improvement = 0\n",
    "        # else:\n",
    "        #     no_improvement += 1\n",
    "\n",
    "        # if no_improvement >= lr_patience:\n",
    "        #     for param_group in optimizer.param_groups:\n",
    "        #         param_group['lr'] /= 2  \n",
    "        #     no_improvement = 0  \n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        torch.save(model.state_dict(), f'{weight_path}/{dataset_name}.pth')\n",
    "\n",
    "    # ----------------------------------------------- Testing process -----------------------------------------------\n",
    "    model = GRAPH_MAMBA(configs)\n",
    "    model.load_state_dict(torch.load(f'{weight_path}/{dataset_name}.pth'))\n",
    "    model.eval() \n",
    "\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_output = model(batch_x)  \n",
    "            true_labels.append(batch_y.numpy())\n",
    "            predictions.append(batch_output.numpy())\n",
    "    \n",
    "    true_labels = np.concatenate(true_labels, axis=0)\n",
    "    predictions = np.squeeze(np.concatenate(predictions, axis=0))\n",
    "\n",
    "    # Save testing plot to a specified path\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(true_labels, label='True Labels', color='blue', alpha=0.7)\n",
    "    plt.plot(predictions, label='Predictions', color='red', alpha=0.7)\n",
    "\n",
    "    plt.title('Model Predictions vs True Labels (Test Data)')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'{plot_save_path}/{dataset_name}.png')  # Save plot to the specified path\n",
    "    plt.close()\n",
    "\n",
    "    test_loss = RMSE(true_labels, predictions)\n",
    "    ic_test = information_coefficient(true_labels, predictions)\n",
    "    ric_test = rank_information_coefficient(true_labels, predictions)\n",
    "    print(f\"Test Loss (RMSE): {test_loss:.4f}\")\n",
    "    print(f\"IC: {ic_test:.4f}\")\n",
    "    print(f\"RIC: {ric_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Peddler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
